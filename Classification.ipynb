{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "%matplotlib inline  \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the wikipedia pages articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_data = pd.read_csv(\"politics_full.csv\")\n",
    "sports_data = pd.read_csv(\"sports_full.csv\")\n",
    "history_data = pd.read_csv(\"history_full.csv\")\n",
    "culture_data = pd.read_csv(\"culture_full.csv\")\n",
    "comp_science_data = pd.read_csv(\"comp_science_full.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping different categories to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = {\n",
    "    1: 'politics',\n",
    "    2: 'sports',\n",
    "    3: 'history',\n",
    "    4: 'culture',\n",
    "    5: 'computer_science'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing newlines and punctuations from raw content of the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = str.maketrans('', '', string.punctuation)\n",
    "politics_data['content'] = politics_data['content'].map(lambda x: re.sub('\\n', ' ', x))\\\n",
    ".map(lambda x: x.translate(translator))\n",
    "politics_data['category'] = [1]* len(politics_data)\n",
    "\n",
    "sports_data['content'] = sports_data['content'].map(lambda x: re.sub('\\n', ' ', x))\\\n",
    ".map(lambda x: x.translate(translator))\n",
    "sports_data['category'] = [2]* len(sports_data)\n",
    "\n",
    "history_data['content'] = history_data['content'].map(lambda x: re.sub('\\n', ' ', x))\\\n",
    ".map(lambda x: x.translate(translator))\n",
    "history_data['category'] = [3]* len(history_data)\n",
    "\n",
    "culture_data['content'] = culture_data['content'].map(lambda x: re.sub('\\n', ' ', x))\\\n",
    ".map(lambda x: x.translate(translator))\n",
    "culture_data['category'] = [4]* len(culture_data)\n",
    "\n",
    "comp_science_data['content'] = comp_science_data['content'].map(lambda x: re.sub('\\n', ' ', x))\\\n",
    ".map(lambda x: x.translate(translator))\n",
    "comp_science_data['category'] = [5]* len(comp_science_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>pageid</th>\n",
       "      <th>length</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Artificial intelligence</td>\n",
       "      <td>1164</td>\n",
       "      <td>231620</td>\n",
       "      <td>Artificial intelligence AI also machine intell...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Comparison of programming languages (string fu...</td>\n",
       "      <td>3681422</td>\n",
       "      <td>109570</td>\n",
       "      <td>String functions are used in computer programm...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Geographic information system</td>\n",
       "      <td>12398</td>\n",
       "      <td>77692</td>\n",
       "      <td>A geographic information system GIS is a syste...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Computational creativity</td>\n",
       "      <td>16300571</td>\n",
       "      <td>61153</td>\n",
       "      <td>Computational creativity also known as artific...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Computational phylogenetics</td>\n",
       "      <td>3986130</td>\n",
       "      <td>58742</td>\n",
       "      <td>Computational phylogenetics is the application...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title    pageid  \\\n",
       "0           0                            Artificial intelligence      1164   \n",
       "1           1  Comparison of programming languages (string fu...   3681422   \n",
       "2           2                      Geographic information system     12398   \n",
       "3           3                           Computational creativity  16300571   \n",
       "4           4                        Computational phylogenetics   3986130   \n",
       "\n",
       "   length                                            content  category  \n",
       "0  231620  Artificial intelligence AI also machine intell...         5  \n",
       "1  109570  String functions are used in computer programm...         5  \n",
       "2   77692  A geographic information system GIS is a syste...         5  \n",
       "3   61153  Computational creativity also known as artific...         5  \n",
       "4   58742  Computational phylogenetics is the application...         5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_science_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Union the 5 dataframes and make a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#union data frames\n",
    "df_list = [politics_data, sports_data, history_data, culture_data, comp_science_data]\n",
    "full_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the rows of dataframe\n",
    "full_df = full_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = list(full_df['content'])\n",
    "targets = np.array(full_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making the TF IDF matrix of the documents. We choose to remove the words that appear in less than 5 documnets in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 31700)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=5)\n",
    "#vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(contents)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the resulting matrix is relatively sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of zeros: 1505991\n",
      "301.1982 average zero per data sample\n"
     ]
    }
   ],
   "source": [
    "print('total number of zeros:', vectors.nnz)\n",
    "print('{} average zero per data sample'.format(vectors.nnz / float(vectors.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is desirable to have equal number of samples in both training and test corpus. So we first shuffle the indicies for each of the classes and then we pick 90% data from each of the classes for training and 10% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies_1 = [i for i,x in enumerate(targets) if x == 1]\n",
    "np.random.shuffle(indicies_1)\n",
    "indicies_2 = [i for i,x in enumerate(targets) if x == 2]\n",
    "np.random.shuffle(indicies_2)\n",
    "indicies_3 = [i for i,x in enumerate(targets) if x == 3]\n",
    "np.random.shuffle(indicies_3)\n",
    "indicies_4 = [i for i,x in enumerate(targets) if x == 4]\n",
    "np.random.shuffle(indicies_4)\n",
    "indicies_5 = [i for i,x in enumerate(targets) if x == 5]\n",
    "np.random.shuffle(indicies_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.9\n",
    "train_indicies = indicies_1[0:int(ratio*len(indicies_1))]\\\n",
    "+indicies_2[0:int(ratio*len(indicies_2))]+indicies_3[0:int(ratio*len(indicies_3))]\\\n",
    "+indicies_4[0:int(ratio*len(indicies_4))]+indicies_5[0:int(ratio*len(indicies_5))]\n",
    "np.random.shuffle(train_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indicies = indicies_1[int(ratio*len(indicies_1)):]\\\n",
    "+indicies_2[int(ratio*len(indicies_2)):]+indicies_3[int(ratio*len(indicies_3)):]\\\n",
    "+indicies_4[int(ratio*len(indicies_4)):]+indicies_5[int(ratio*len(indicies_5)):]\n",
    "np.random.shuffle(test_indicies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final training and test vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = vectors[train_indicies]\n",
    "test_vectors = vectors[test_indicies]\n",
    "#------------\n",
    "train_targets = targets[train_indicies]\n",
    "test_targets = targets[test_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '000', '0000', '001', '007']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fisrt we choose to train a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFclassifier = RandomForestClassifier(n_jobs=-1)\n",
    "RFclassifier.fit(train_vectors,train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = RFclassifier.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 74.6%\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean([test_res[i]==test_targets[i] for i in range(len(test_targets))])\n",
    "print('accuracy = {}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning for Random Forest parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], 'max_depth': [50, 60, 70, 80, 90]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "n_estimator = [i for i in range(100,1100,100)]\n",
    "max_depth = [i for i in range(50,100,10)]\n",
    "clf = GridSearchCV(estimator=RFclassifier, param_grid={'n_estimators':n_estimator,'max_depth':max_depth},n_jobs=-1)\n",
    "clf.fit(train_vectors,train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe below shows the best train and test score and their associated parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajalloei/.conda/envs/ahmad_virtualenv/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ajalloei/.conda/envs/ahmad_virtualenv/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ajalloei/.conda/envs/ahmad_virtualenv/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ajalloei/.conda/envs/ahmad_virtualenv/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ajalloei/.conda/envs/ahmad_virtualenv/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>163.670287</td>\n",
       "      <td>7.145987</td>\n",
       "      <td>0.821556</td>\n",
       "      <td>0.990333</td>\n",
       "      <td>70</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 70, 'n_estimators': 1000}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814667</td>\n",
       "      <td>0.992333</td>\n",
       "      <td>0.823333</td>\n",
       "      <td>0.990333</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.988333</td>\n",
       "      <td>11.686875</td>\n",
       "      <td>1.077985</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.001633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>125.858999</td>\n",
       "      <td>6.559073</td>\n",
       "      <td>0.821111</td>\n",
       "      <td>0.989222</td>\n",
       "      <td>50</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 900}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.825333</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.824667</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>1.134310</td>\n",
       "      <td>0.123111</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.002378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>150.759535</td>\n",
       "      <td>7.794189</td>\n",
       "      <td>0.821111</td>\n",
       "      <td>0.989111</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 1000}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.814667</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.823333</td>\n",
       "      <td>0.989667</td>\n",
       "      <td>0.825333</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>7.780510</td>\n",
       "      <td>0.247463</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>119.400220</td>\n",
       "      <td>5.967087</td>\n",
       "      <td>0.821111</td>\n",
       "      <td>0.989778</td>\n",
       "      <td>60</td>\n",
       "      <td>700</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 700}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.990333</td>\n",
       "      <td>0.819333</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>5.114454</td>\n",
       "      <td>0.159478</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.002079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>157.372489</td>\n",
       "      <td>7.499259</td>\n",
       "      <td>0.820889</td>\n",
       "      <td>0.989778</td>\n",
       "      <td>60</td>\n",
       "      <td>900</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 900}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.814667</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.990333</td>\n",
       "      <td>0.821333</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>2.454800</td>\n",
       "      <td>0.460805</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>0.002079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "29     163.670287         7.145987         0.821556          0.990333   \n",
       "8      125.858999         6.559073         0.821111          0.989222   \n",
       "9      150.759535         7.794189         0.821111          0.989111   \n",
       "16     119.400220         5.967087         0.821111          0.989778   \n",
       "18     157.372489         7.499259         0.820889          0.989778   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "29              70               1000   \n",
       "8               50                900   \n",
       "9               50               1000   \n",
       "16              60                700   \n",
       "18              60                900   \n",
       "\n",
       "                                     params  rank_test_score  \\\n",
       "29  {'max_depth': 70, 'n_estimators': 1000}                1   \n",
       "8    {'max_depth': 50, 'n_estimators': 900}                2   \n",
       "9   {'max_depth': 50, 'n_estimators': 1000}                2   \n",
       "16   {'max_depth': 60, 'n_estimators': 700}                2   \n",
       "18   {'max_depth': 60, 'n_estimators': 900}                5   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "29           0.814667            0.992333           0.823333   \n",
       "8            0.813333            0.991667           0.825333   \n",
       "9            0.814667            0.991667           0.823333   \n",
       "16           0.814000            0.992000           0.830000   \n",
       "18           0.814667            0.992000           0.826667   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "29            0.990333           0.826667            0.988333     11.686875   \n",
       "8             0.990000           0.824667            0.986000      1.134310   \n",
       "9             0.989667           0.825333            0.986000      7.780510   \n",
       "16            0.990333           0.819333            0.987000      5.114454   \n",
       "18            0.990333           0.821333            0.987000      2.454800   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "29        1.077985        0.005058         0.001633  \n",
       "8         0.123111        0.005506         0.002378  \n",
       "9         0.247463        0.004629         0.002347  \n",
       "16        0.159478        0.006652         0.002079  \n",
       "18        0.460805        0.004909         0.002079  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df.sort_values('rank_test_score',inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=70, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_RFclassifier = RandomForestClassifier(n_estimators=1000, max_depth=70, n_jobs=-1)\n",
    "best_RFclassifier.fit(train_vectors,train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for best RF classifier = 82.8%\n"
     ]
    }
   ],
   "source": [
    "print('accuracy for best RF classifier = {}%'.format(best_RFclassifier.score(test_vectors, test_targets)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second classifier is Multinomial Naive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(train_vectors, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Multinomial Naive Bayes classifier = 84.0%\n"
     ]
    }
   ],
   "source": [
    "print('accuracy for Multinomial Naive Bayes classifier = {}%'.format(clf.score(test_vectors, test_targets)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning $\\alpha $ parameter for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = [i/10 for i in range(1,20,1)]\n",
    "clf = GridSearchCV(estimator=MultinomialNB(), param_grid={'alpha':alpha},n_jobs=-1, cv=10, return_train_score=True)\n",
    "clf.fit(train_vectors,train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.337634</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>0.845778</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'alpha': 0.2}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.931605</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.934074</td>\n",
       "      <td>0.851111</td>\n",
       "      <td>0.933086</td>\n",
       "      <td>0.023646</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.236525</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.940889</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.940741</td>\n",
       "      <td>0.851111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848889</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.848889</td>\n",
       "      <td>0.940247</td>\n",
       "      <td>0.105323</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>0.010669</td>\n",
       "      <td>0.001646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.307943</td>\n",
       "      <td>0.011466</td>\n",
       "      <td>0.842889</td>\n",
       "      <td>0.927333</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'alpha': 0.3}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.927654</td>\n",
       "      <td>0.842222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855556</td>\n",
       "      <td>0.925679</td>\n",
       "      <td>0.824444</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.842222</td>\n",
       "      <td>0.927654</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>0.012998</td>\n",
       "      <td>0.001018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.295297</td>\n",
       "      <td>0.012531</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.922123</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'alpha': 0.4}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.862222</td>\n",
       "      <td>0.923951</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.817778</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.923210</td>\n",
       "      <td>0.023494</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.013481</td>\n",
       "      <td>0.001750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229445</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.838222</td>\n",
       "      <td>0.917654</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.851111</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.835556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851111</td>\n",
       "      <td>0.915802</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.918272</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.919012</td>\n",
       "      <td>0.091586</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>0.001185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "1       0.337634         0.010722         0.845778          0.933333   \n",
       "0       0.236525         0.008792         0.843333          0.940889   \n",
       "2       0.307943         0.011466         0.842889          0.927333   \n",
       "3       0.295297         0.012531         0.840000          0.922123   \n",
       "4       0.229445         0.008891         0.838222          0.917654   \n",
       "\n",
       "  param_alpha          params  rank_test_score  split0_test_score  \\\n",
       "1         0.2  {'alpha': 0.2}                1           0.866667   \n",
       "0         0.1  {'alpha': 0.1}                2           0.860000   \n",
       "2         0.3  {'alpha': 0.3}                3           0.866667   \n",
       "3         0.4  {'alpha': 0.4}                4           0.862222   \n",
       "4         0.5  {'alpha': 0.5}                5           0.851111   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split7_test_score  \\\n",
       "1            0.933333           0.853333       ...                  0.853333   \n",
       "0            0.940741           0.851111       ...                  0.848889   \n",
       "2            0.927654           0.842222       ...                  0.855556   \n",
       "3            0.923951           0.833333       ...                  0.853333   \n",
       "4            0.918519           0.835556       ...                  0.851111   \n",
       "\n",
       "   split7_train_score  split8_test_score  split8_train_score  \\\n",
       "1            0.931605           0.831111            0.934074   \n",
       "0            0.938272           0.831111            0.940000   \n",
       "2            0.925679           0.824444            0.927901   \n",
       "3            0.920000           0.817778            0.922222   \n",
       "4            0.915802           0.820000            0.918272   \n",
       "\n",
       "   split9_test_score  split9_train_score  std_fit_time  std_score_time  \\\n",
       "1           0.851111            0.933086      0.023646        0.002840   \n",
       "0           0.848889            0.940247      0.105323        0.004253   \n",
       "2           0.842222            0.927654      0.019358        0.002061   \n",
       "3           0.833333            0.923210      0.023494        0.001517   \n",
       "4           0.831111            0.919012      0.091586        0.003984   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "1        0.012500         0.001059  \n",
       "0        0.010669         0.001646  \n",
       "2        0.012998         0.001018  \n",
       "3        0.013481         0.001750  \n",
       "4        0.010968         0.001185  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(clf.cv_results_)\n",
    "df.sort_values('rank_test_score',inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for best Multinomial Naive Bayes classifier = 84.8%\n"
     ]
    }
   ],
   "source": [
    "best_NB = MultinomialNB(alpha=0.2).fit(train_vectors, train_targets)\n",
    "print('accuracy for best Multinomial Naive Bayes classifier = {}%'.format(best_NB.score(test_vectors, test_targets)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a multiclass Logestic Regression for the task. We use the Logistic Regression cross validation function. The rgularization parameter will vary between $10ˆ{-4}$ and $10ˆ{4}$. We choose to have 20 different values in this interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=20, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='multinomial', n_jobs=-1, penalty='l2',\n",
       "           random_state=None, refit=True, scoring=None, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "clf = LogisticRegressionCV(Cs=20, multi_class='multinomial', n_jobs=-1)\n",
    "clf.fit(train_vectors, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for best Logistic Regression classifier = 87.8%\n"
     ]
    }
   ],
   "source": [
    "print('accuracy for best Logistic Regression classifier = {}%'.format(clf.score(test_vectors, test_targets)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "scors = np.concatenate((np.mean(clf.scores_[1], axis = 0), np.mean(clf.scores_[2], axis = 0)\n",
    "                        , np.mean(clf.scores_[3], axis = 0), np.mean(clf.scores_[4], axis = 0)\n",
    "                        , np.mean(clf.scores_[5], axis = 0)), axis=0)\n",
    "scors = scors.reshape((5,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f365c1506a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(clf.Cs_, np.mean(scors, axis=0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "test_res = clf.predict(test_vectors)\n",
    "cnf_matrix = confusion_matrix(test_targets, test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f35dc091f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(category_dict))\n",
    "    plt.xticks(tick_marks, category_dict.values(), rotation=90,fontsize=12)\n",
    "    plt.yticks(tick_marks, category_dict.values(), fontsize=12)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',fontsize = 15)\n",
    "    plt.xlabel('Predicted label',fontsize = 15)\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cnf_matrix, classes=newsgroups.target_names,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix show wich classes where misclassified with each other. As expected similar categories (culture, politics and history) were misclassified mostly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the deep learning part here. We will use Keras library on Tensorflow backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajalloei/.conda/envs/ahmad_virtualenv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the deep learning part we will use word embeddings as they are proved to give better results compared to one hot word vectors. So we start to tokenize the text again with nltk library and remove the stop words. We also lower case all of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenized = [nltk.word_tokenize(text) for text in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# punctuation = string.punctuation+'“’—.”’“--,”' # pimp the list of punctuation to remove\n",
    "def rem_stop(txt,stop_words=stopwords.words(\"english\"),lower=True):\n",
    "    \"\"\"\n",
    "    Removes stopwords and other things from a text, inc. numbers\n",
    "    :param list txt: text tokens (list of str)\n",
    "    :param list stop_words: stopwords to remove (list of str)\n",
    "    :param bol lower: if to lowercase\n",
    "    \"\"\"\n",
    "    if lower:\n",
    "        return [t.lower() for t in txt if t.lower() not in stop_words and not t.isdigit()]\n",
    "    else:\n",
    "        return [t for t in txt if t.lower() not in stop_words and not t.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [rem_stop(tokens) for tokens in tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = Word2Vec(corpus, size=100, window=5, min_count=1, workers=-1, iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('post1970s', 0.45103001594543457),\n",
       " ('lacierda', 0.4451066255569458),\n",
       " ('forgacs', 0.4363461434841156),\n",
       " ('repealing', 0.4331750273704529),\n",
       " ('interregnums', 0.4275933504104614),\n",
       " ('u818', 0.421070396900177),\n",
       " ('abcdef', 0.4119409918785095),\n",
       " ('doi10100735404755597', 0.39712589979171753),\n",
       " ('welsch', 0.396402508020401),\n",
       " ('commandinchief', 0.391961932182312)]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.wv.most_similar(positive=['france', 'paris'], negative=['germany'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Embedding, LSTM, Conv1D, Flatten, Dropout\n",
    "from keras.layers.merge import Concatenate, concatenate\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 175282 unique tokens.\n",
      "Shape of data tensor: (5000, 5000)\n",
      "Shape of label tensor: (5000, 5)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 5000\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "# 0 is a reserved index that won't be assigned to any word\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(targets-1))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175282"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[train_indicies]\n",
    "y_train = labels[train_indicies]\n",
    "x_test = data[test_indicies]\n",
    "y_test = labels[test_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING_DIM = 100\n",
    "# embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "# for word, i in word_index.items():\n",
    "#     embedding_vector = embedding_model.wv.vocab.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         # words not found in embedding index will be all-zeros.\n",
    "#         embedding_matrix[i] = embedding_model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_callback = ModelCheckpoint('keras_model', \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1, \n",
    "                                 save_best_only=True, \n",
    "                                 mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4050 samples, validate on 450 samples\n",
      "Epoch 1/10\n",
      "4050/4050 [==============================] - 47s 12ms/step - loss: 4.7758 - acc: 0.3551 - val_loss: 2.6198 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.61980, saving model to keras_model\n",
      "Epoch 2/10\n",
      "4050/4050 [==============================] - 46s 11ms/step - loss: 1.3508 - acc: 0.6733 - val_loss: 0.9727 - val_acc: 0.6578\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.61980 to 0.97270, saving model to keras_model\n",
      "Epoch 3/10\n",
      "4050/4050 [==============================] - 46s 11ms/step - loss: 0.7054 - acc: 0.7919 - val_loss: 0.7638 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.97270 to 0.76383, saving model to keras_model\n",
      "Epoch 4/10\n",
      "4050/4050 [==============================] - 47s 11ms/step - loss: 0.4252 - acc: 0.8716 - val_loss: 0.8615 - val_acc: 0.6778\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/10\n",
      "4050/4050 [==============================] - 46s 11ms/step - loss: 0.3324 - acc: 0.8973 - val_loss: 0.4882 - val_acc: 0.8444\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.76383 to 0.48820, saving model to keras_model\n",
      "Epoch 6/10\n",
      "4050/4050 [==============================] - 46s 11ms/step - loss: 0.4785 - acc: 0.8847 - val_loss: 0.4554 - val_acc: 0.8556\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.48820 to 0.45536, saving model to keras_model\n",
      "Epoch 7/10\n",
      "4050/4050 [==============================] - 47s 12ms/step - loss: 0.1787 - acc: 0.9528 - val_loss: 0.4460 - val_acc: 0.8622\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.45536 to 0.44604, saving model to keras_model\n",
      "Epoch 8/10\n",
      "4050/4050 [==============================] - 47s 12ms/step - loss: 0.2069 - acc: 0.9338 - val_loss: 0.6305 - val_acc: 0.8089\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/10\n",
      "4050/4050 [==============================] - 46s 11ms/step - loss: 0.1257 - acc: 0.9669 - val_loss: 0.4778 - val_acc: 0.8556\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/10\n",
      "4050/4050 [==============================] - 46s 11ms/step - loss: 0.0935 - acc: 0.9746 - val_loss: 0.9012 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b962aca90>"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "# x = Conv1D(128, 5, activation='relu')(x)\n",
    "# x = MaxPooling1D(5)(x)\n",
    "# x = Conv1D(128, 5, activation='relu')(x)\n",
    "# x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Dropout(0.25)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(len(category_dict), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# happy learning!\n",
    "model.fit(x_train, y_train, validation_split=0.1, \n",
    "          epochs=10, batch_size=512, callbacks=[ckpt_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 3s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5528527736663819, 0.83]"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model = load_model('keras_model')\n",
    "keras_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 5000, 100)         17528300  \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 196)               232848    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 5)                 985       \n",
      "=================================================================\n",
      "Total params: 17,762,133\n",
      "Trainable params: 17,762,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# embed_dim = 100\n",
    "lstm_out = 196\n",
    "\n",
    "# Model saving callback\n",
    "lstm_callback = ModelCheckpoint('lstm_model', \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1, \n",
    "                                 save_best_only=True, \n",
    "                                 mode='auto')\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(embedding_layer)\n",
    "lstm_model.add(LSTM(lstm_out, recurrent_dropout=0.2, dropout=0.2))\n",
    "lstm_model.add(Dense(5,activation='softmax'))\n",
    "lstm_model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['acc'])\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4050 samples, validate on 450 samples\n",
      "Epoch 1/20\n",
      "4050/4050 [==============================] - 224s 55ms/step - loss: 1.4419 - acc: 0.4627 - val_loss: 1.1370 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.13701, saving model to lstm_model\n",
      "Epoch 2/20\n",
      "4050/4050 [==============================] - 219s 54ms/step - loss: 0.8628 - acc: 0.7143 - val_loss: 0.7540 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.13701 to 0.75403, saving model to lstm_model\n",
      "Epoch 3/20\n",
      "4050/4050 [==============================] - 219s 54ms/step - loss: 0.6125 - acc: 0.7812 - val_loss: 0.6536 - val_acc: 0.7667\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.75403 to 0.65361, saving model to lstm_model\n",
      "Epoch 4/20\n",
      "4050/4050 [==============================] - 221s 55ms/step - loss: 0.4946 - acc: 0.8281 - val_loss: 0.5911 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.65361 to 0.59115, saving model to lstm_model\n",
      "Epoch 5/20\n",
      "4050/4050 [==============================] - 220s 54ms/step - loss: 0.4395 - acc: 0.8560 - val_loss: 0.5762 - val_acc: 0.7933\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.59115 to 0.57622, saving model to lstm_model\n",
      "Epoch 6/20\n",
      "4050/4050 [==============================] - 222s 55ms/step - loss: 0.3792 - acc: 0.8719 - val_loss: 0.5854 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/20\n",
      "4050/4050 [==============================] - 221s 55ms/step - loss: 0.3521 - acc: 0.8847 - val_loss: 0.5882 - val_acc: 0.8067\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/20\n",
      "4050/4050 [==============================] - 222s 55ms/step - loss: 0.3207 - acc: 0.8975 - val_loss: 0.5701 - val_acc: 0.8133\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.57622 to 0.57012, saving model to lstm_model\n",
      "Epoch 9/20\n",
      "4050/4050 [==============================] - 220s 54ms/step - loss: 0.2942 - acc: 0.9072 - val_loss: 0.5799 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/20\n",
      "4050/4050 [==============================] - 220s 54ms/step - loss: 0.2861 - acc: 0.9057 - val_loss: 0.5763 - val_acc: 0.8044\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "4050/4050 [==============================] - 222s 55ms/step - loss: 0.2545 - acc: 0.9178 - val_loss: 0.5981 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/20\n",
      "4050/4050 [==============================] - 221s 55ms/step - loss: 0.2302 - acc: 0.9272 - val_loss: 0.5904 - val_acc: 0.8178\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "4050/4050 [==============================] - 222s 55ms/step - loss: 0.2201 - acc: 0.9284 - val_loss: 0.5490 - val_acc: 0.8111\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.57012 to 0.54901, saving model to lstm_model\n",
      "Epoch 14/20\n",
      "4050/4050 [==============================] - 219s 54ms/step - loss: 0.2417 - acc: 0.9215 - val_loss: 0.6178 - val_acc: 0.7889\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "4050/4050 [==============================] - 220s 54ms/step - loss: 0.1969 - acc: 0.9400 - val_loss: 0.6610 - val_acc: 0.8089\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/20\n",
      "4050/4050 [==============================] - 220s 54ms/step - loss: 0.1971 - acc: 0.9353 - val_loss: 0.5945 - val_acc: 0.8133\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "4050/4050 [==============================] - 221s 55ms/step - loss: 0.1741 - acc: 0.9452 - val_loss: 0.5830 - val_acc: 0.8044\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "4050/4050 [==============================] - 223s 55ms/step - loss: 0.1547 - acc: 0.9521 - val_loss: 0.6230 - val_acc: 0.8089\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "2048/4050 [==============>...............] - ETA: 1:44 - loss: 0.1355 - acc: 0.9614"
     ]
    }
   ],
   "source": [
    "lstm_model.fit(x_train, y_train, validation_split=0.1, verbose=1,\n",
    "          epochs=20, batch_size=512, callbacks=[lstm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 33s 66ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5823710279464722, 0.8100000004768372]"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lstm_model = load_model('lstm_model')\n",
    "best_lstm_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_4 (Merge)              (None, 324)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 5)                 1625      \n",
      "=================================================================\n",
      "Total params: 51,722,945\n",
      "Trainable params: 51,722,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajalloei/.conda/envs/ahmad_virtualenv/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "embedding_layer1 = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "cnn = Sequential()\n",
    "cnn.add(embedding_layer1)\n",
    "cnn.add(Conv1D(128, 5, activation='relu'))\n",
    "cnn.add(MaxPooling1D(5))\n",
    "cnn.add(Dropout(0.25))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "\n",
    "lstm_out = 196\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(embedding_layer)\n",
    "lstm.add(LSTM(lstm_out, recurrent_dropout=0.2, dropout=0.2))\n",
    "\n",
    "merged = Merge([cnn, lstm], mode='concat')\n",
    "\n",
    "merged_model = Sequential()\n",
    "merged_model.add(merged)\n",
    "merged_model.add(Dense(len(category_dict), activation='softmax'))\n",
    "# merged_model.add(Dropout(0.5))\n",
    "# merged_model.add(Dense(28, activation='relu'))\n",
    "# merged_model.add(Dense(input_dim=10, output_dim=classes))\n",
    "# merged_model.add(Activation(\"softmax\"))\n",
    "merged_model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['acc'])\n",
    "print(merged_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4050 samples, validate on 450 samples\n",
      "Epoch 1/10\n",
      "4050/4050 [==============================] - 250s 62ms/step - loss: 4.4642 - acc: 0.3007 - val_loss: 2.4140 - val_acc: 0.3711\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.41395, saving model to merged_model\n",
      "Epoch 2/10\n",
      "4050/4050 [==============================] - 243s 60ms/step - loss: 1.7234 - acc: 0.5521 - val_loss: 1.0846 - val_acc: 0.6711\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.41395 to 1.08465, saving model to merged_model\n",
      "Epoch 3/10\n",
      "4050/4050 [==============================] - 246s 61ms/step - loss: 0.7507 - acc: 0.7598 - val_loss: 0.6483 - val_acc: 0.7733\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.08465 to 0.64834, saving model to merged_model\n",
      "Epoch 4/10\n",
      "4050/4050 [==============================] - 246s 61ms/step - loss: 0.4488 - acc: 0.8627 - val_loss: 0.6033 - val_acc: 0.7867\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.64834 to 0.60331, saving model to merged_model\n",
      "Epoch 5/10\n",
      "4050/4050 [==============================] - 246s 61ms/step - loss: 0.3062 - acc: 0.9091 - val_loss: 0.5933 - val_acc: 0.7911\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.60331 to 0.59331, saving model to merged_model\n",
      "Epoch 6/10\n",
      "4050/4050 [==============================] - 248s 61ms/step - loss: 0.2236 - acc: 0.9358 - val_loss: 0.6394 - val_acc: 0.8156\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/10\n",
      "4050/4050 [==============================] - 248s 61ms/step - loss: 0.1721 - acc: 0.9440 - val_loss: 0.6089 - val_acc: 0.8133\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/10\n",
      "4050/4050 [==============================] - 247s 61ms/step - loss: 0.1462 - acc: 0.9563 - val_loss: 0.6057 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/10\n",
      "4050/4050 [==============================] - 249s 61ms/step - loss: 0.1254 - acc: 0.9620 - val_loss: 0.6381 - val_acc: 0.8111\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/10\n",
      "4050/4050 [==============================] - 254s 63ms/step - loss: 0.1055 - acc: 0.9679 - val_loss: 0.5985 - val_acc: 0.8133\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b95a324a8>"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_callback = ModelCheckpoint('merged_model', \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1, \n",
    "                                 save_best_only=True, \n",
    "                                 mode='auto')\n",
    "merged_model.fit([x_train, x_train], y_train, validation_split=0.1, verbose=1,\n",
    "          epochs=10, batch_size=512, callbacks=[merged_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Dropout(0.25)(x)\n",
    "# x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = LSTM(lstm_out, recurrent_dropout=0.25, dropout=0.25)(x)\n",
    "preds = Dense(len(category_dict), activation='softmax')(x)\n",
    "\n",
    "mixed_model = Model(sequence_input, preds)\n",
    "mixed_model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4050 samples, validate on 450 samples\n",
      "Epoch 1/15\n",
      "4050/4050 [==============================] - 86s 21ms/step - loss: 1.3689 - acc: 0.4881 - val_loss: 0.8911 - val_acc: 0.7267\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.89108, saving model to mixed_model1\n",
      "Epoch 2/15\n",
      "4050/4050 [==============================] - 84s 21ms/step - loss: 0.5549 - acc: 0.8341 - val_loss: 0.5255 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.89108 to 0.52550, saving model to mixed_model1\n",
      "Epoch 3/15\n",
      "4050/4050 [==============================] - 83s 21ms/step - loss: 0.2463 - acc: 0.9175 - val_loss: 0.6100 - val_acc: 0.8178\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/15\n",
      "4050/4050 [==============================] - 84s 21ms/step - loss: 0.1408 - acc: 0.9600 - val_loss: 0.6401 - val_acc: 0.8156\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/15\n",
      "4050/4050 [==============================] - 84s 21ms/step - loss: 0.0865 - acc: 0.9709 - val_loss: 0.6233 - val_acc: 0.8067\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/15\n",
      "4050/4050 [==============================] - 84s 21ms/step - loss: 0.0685 - acc: 0.9760 - val_loss: 0.7155 - val_acc: 0.8156\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/15\n",
      "4050/4050 [==============================] - 85s 21ms/step - loss: 0.0535 - acc: 0.9837 - val_loss: 0.7042 - val_acc: 0.8156\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/15\n",
      "4050/4050 [==============================] - 84s 21ms/step - loss: 0.0453 - acc: 0.9852 - val_loss: 0.7632 - val_acc: 0.8156\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/15\n"
     ]
    }
   ],
   "source": [
    "mixed_callback = ModelCheckpoint('mixed_model1', \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1, \n",
    "                                 save_best_only=True, \n",
    "                                 mode='auto')\n",
    "# happy learning!\n",
    "mixed_model.fit(x_train, y_train, validation_split=0.1, \n",
    "          epochs=15, batch_size=512, callbacks=[mixed_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 8s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5140607929229737, 0.7899999995231628]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mixed_model = load_model('mixed_model1')\n",
    "best_mixed_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3579a05630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = [len(t) for t in corpus]\n",
    "plt.hist(l, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 5000, 100)         17528300  \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 4996, 100)         50100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 999, 100)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 999, 100)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 99900)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               12787328  \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 30,366,373\n",
      "Trainable params: 30,366,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_cnn_model = load_model('best_cnn_model')\n",
    "best_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.642090087890625, 0.8160000009536743]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cnn_model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
